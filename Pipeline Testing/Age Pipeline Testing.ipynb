{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\caron\\OneDrive - University of North Carolina at Chapel Hill\\Honors Project\\CSV Files\\MRI Data.csv')\n",
    "for i in range(0, 1911): # getting only healthy data for sex pipeline\n",
    "    if (df.loc[i, 'SDx'] == 3):\n",
    "        df = df.drop([i])\n",
    "avg_age = df['Age'].mean() # avearage age of healthy subjects\n",
    "for i in range(0, df.shape[0]):\n",
    "    if (df.loc[i, 'Age'] > avg_age):\n",
    "        df.at[i, 'Age'] = 4\n",
    "    else:\n",
    "        df.at[i, 'Age'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Cross Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([df.loc[0:, ['Age']], df.loc[0:, 'L_LatVent': 'R_insula_surfavg']], axis=1, sort=False)\n",
    "temp = temp.dropna(how='any')\n",
    "df1 = temp.loc[0:, ['Age']]\n",
    "df2 = temp.loc[0:, 'L_LatVent': 'R_insula_surfavg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = pd.concat([df.loc[0:, ['Age']], df.loc[0:, 'L_LatVent': 'R_insula_surfavg']], axis=1, sort=False).dropna(how='any').sample(frac=1).reset_index(drop=True)  \n",
    "train = temp2[:523]\n",
    "test = temp2[523:]\n",
    "df1_train = train.loc[0:, ['Age']]\n",
    "df2_train = train.loc[0:, 'L_LatVent': 'R_insula_surfavg']\n",
    "df1_test = test.loc[0:, ['Age']]\n",
    "df2_test = test.loc[0:, 'L_LatVent': 'R_insula_surfavg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df1).ravel()\n",
    "x = np.array(df2)\n",
    "y_train = np.array(df1_train).ravel()\n",
    "x_train = np.array(df2_train)\n",
    "y_test = np.array(df1_test).ravel()\n",
    "x_test = np.array(df2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Normalization Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMax = MinMaxScaler()\n",
    "robust = RobustScaler()\n",
    "standard = StandardScaler()\n",
    "quantile = QuantileTransformer()\n",
    "normal = Normalizer()\n",
    "power = PowerTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability=True, gamma ='scale')\n",
    "lsvc = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl1 = Pipeline([('minMax', minMax), ('svc', svc)])\n",
    "# linearSVC with min max pl1b\n",
    "pl1b = Pipeline([('minMax', minMax), ('lsvc', lsvc)])\n",
    "pl1c = Pipeline([('minMax', minMax), ('svc', svc)])# svc/minMax w/ linear kernel\n",
    "pl2 = Pipeline([('robust', robust), ('svc', svc)])\n",
    "pl3 = Pipeline([('standard', standard), ('svc', svc)])\n",
    "pl4 = Pipeline([('quantile', quantile), ('svc', svc)])\n",
    "pl5 = Pipeline([('normal', normal), ('svc', svc)])\n",
    "pl6 = Pipeline([('power', power), ('svc', svc)])\n",
    "plall = Pipeline([('minMax', minMax), ('robust', robust), ('standard', standard), ('quantile', quantile), ('normal', normal), ('power', power), ('svc', svc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pl1 (minMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7153834115805946\n",
      "\n",
      "best params: {'svc__C': 0.9}\n",
      "\n",
      "best index: 1\n"
     ]
    }
   ],
   "source": [
    "parameters1 = {'svc__C':(0.8, 0.9, 1)}\n",
    "cv1 = GridSearchCV(pl1, parameters1, iid = False, cv=10)\n",
    "cv1.fit(x, y)\n",
    "\n",
    "print('best score:', end=\" \")\n",
    "print(cv1.best_score_)\n",
    "print('\\nbest params:', end=\" \")\n",
    "print(cv1.best_params_)\n",
    "print('\\nbest index:', end=\" \")\n",
    "print(cv1.best_index_)\n",
    "#print('\\nbest estimator:')\n",
    "#print(cv1.best_estimator_)\n",
    "#print(pd.DataFrame(data=cv1.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pl1b (minMax w/ lsvc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform features by scaling each feature to a given range.\n",
    "* LinearSVC would be better for large (10's of thousands) data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7293298680974738\n",
      "\n",
      "best params: {'lsvc__C': 0.04}\n",
      "\n",
      "best index: 1\n"
     ]
    }
   ],
   "source": [
    "parameters1b = {'lsvc__C':(0.03, 0.04, 0.05)}\n",
    "cv1b = GridSearchCV(pl1b, parameters1b, iid = False, cv=10)\n",
    "cv1b.fit(x, y)\n",
    "\n",
    "print('best score:', end=\" \")\n",
    "print(cv1b.best_score_)\n",
    "print('\\nbest params:', end=\" \")\n",
    "print(cv1b.best_params_)\n",
    "print('\\nbest index:', end=\" \")\n",
    "print(cv1b.best_index_)\n",
    "#print('\\nbest estimator:')\n",
    "#print(cv1b.best_estimator_)\n",
    "#print(pd.DataFrame(data=cv1b.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pl1c (minMax w/ linear kernel only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sigmoid and linear for kernel: will always use linear because sigmoid is worse\n",
    "* For surfice model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7222071316789627\n",
      "\n",
      "best params: {'svc__C': 0.1, 'svc__kernel': 'linear'}\n",
      "\n",
      "best index: 3\n"
     ]
    }
   ],
   "source": [
    "parameters1c = {'svc__kernel':('sigmoid', 'linear'), 'svc__C':(.09, .1, .2)}\n",
    "cv1c = GridSearchCV(pl1c, parameters1c, iid = False, cv=10)\n",
    "cv1c.fit(x, y)\n",
    "\n",
    "print('best score:', end=\" \")\n",
    "print(cv1c.best_score_)\n",
    "print('\\nbest params:', end=\" \")\n",
    "print(cv1c.best_params_)\n",
    "print('\\nbest index:', end=\" \")\n",
    "print(cv1c.best_index_)\n",
    "#print('\\nbest estimator:')\n",
    "#print(cv1c.best_estimator_)\n",
    "#print(pd.DataFrame(data=cv1c.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pl2 (robust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scale features using statistics that are robust to outliers.\n",
    "* use pl1 to narrow down to rbf for al other normalizers/processors\n",
    "* made decision based on scores to us rbf for rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7322864967583278\n",
      "\n",
      "best params: {'svc__C': 0.01, 'svc__kernel': 'linear'}\n",
      "\n",
      "best index: 1\n"
     ]
    }
   ],
   "source": [
    "parameters2 = {'svc__kernel':('sigmoid', 'linear'), 'svc__C':(.01, .02)}\n",
    "cv2 = GridSearchCV(pl2, parameters2, iid = False, cv=10)\n",
    "cv2.fit(x, y)\n",
    "\n",
    "print('best score:', end=\" \")\n",
    "print(cv2.best_score_)\n",
    "print('\\nbest params:', end=\" \")\n",
    "print(cv2.best_params_)\n",
    "print('\\nbest index:', end=\" \")\n",
    "print(cv2.best_index_)\n",
    "#print('\\nbest estimator:')\n",
    "#print(cv2.best_estimator_)\n",
    "#print(pd.DataFrame(data=cv2.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pl3 (standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \tStandardize features by removing the mean and scaling to unit variance\n",
    "* use pl1 to narrow down to rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7224463447350771\n",
      "\n",
      "best params: {'svc__C': 1}\n",
      "\n",
      "best index: 1\n"
     ]
    }
   ],
   "source": [
    "parameters3 = {'svc__C':(.9, 1, 1.1)}\n",
    "cv3 = GridSearchCV(pl3, parameters3, iid = False, cv=10)\n",
    "cv3.fit(x, y)\n",
    "\n",
    "print('best score:', end=\" \")\n",
    "print(cv3.best_score_)\n",
    "print('\\nbest params:', end=\" \")\n",
    "print(cv3.best_params_)\n",
    "print('\\nbest index:', end=\" \")\n",
    "print(cv3.best_index_)\n",
    "#print('\\nbest estimator:')\n",
    "#print(cv3.best_estimator_)\n",
    "#print(pd.DataFrame(data=cv3.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pl4 (quantile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform features using quantiles information.\n",
    "* use pl1 to narrow down to rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (634). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (634). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (634). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (634). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (634). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (634). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (635). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (636). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (706). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7337161860049184\n",
      "\n",
      "best params: {'svc__C': 0.09, 'svc__kernel': 'linear'}\n",
      "\n",
      "best index: 3\n"
     ]
    }
   ],
   "source": [
    "parameters4 = {'svc__kernel':('sigmoid', 'linear'), 'svc__C':(.08, .09, .1)}\n",
    "cv4 = GridSearchCV(pl4, parameters4, iid = False, cv=10)\n",
    "cv4.fit(x, y)\n",
    "\n",
    "print('best score:', end=\" \")\n",
    "print(cv4.best_score_)\n",
    "print('\\nbest params:', end=\" \")\n",
    "print(cv4.best_params_)\n",
    "print('\\nbest index:', end=\" \")\n",
    "print(cv4.best_index_)\n",
    "#print('\\nbest estimator:')\n",
    "#print(cv4.best_estimator_)\n",
    "#print(pd.DataFrame(data=cv4.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pl5 (normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Normalize samples individually to unit norm.\n",
    "* use pl1 to narrow down to rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6827246814218645\n",
      "\n",
      "best params: {'svc__C': 5}\n",
      "\n",
      "best index: 1\n"
     ]
    }
   ],
   "source": [
    "parameters5 = {'svc__C':(4, 5, 6)}\n",
    "cv5 = GridSearchCV(pl5, parameters5, iid = False, cv=10)\n",
    "cv5.fit(x, y)\n",
    "\n",
    "print('best score:', end=\" \")\n",
    "print(cv5.best_score_)\n",
    "print('\\nbest params:', end=\" \")\n",
    "print(cv5.best_params_)\n",
    "print('\\nbest index:', end=\" \")\n",
    "print(cv5.best_index_)\n",
    "#print('\\nbest estimator:')\n",
    "#print(cv5.best_estimator_)\n",
    "#print(pd.DataFrame(data=cv5.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pl6 (power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply a power transform featurewise to make data more Gaussian-like.\n",
    "* use pl1 to narrow down to rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\caron\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7182986809747373\n",
      "\n",
      "best params: {'svc__C': 1}\n",
      "\n",
      "best index: 1\n"
     ]
    }
   ],
   "source": [
    "parameters6 = {'svc__C':(.9, 1, 1.1)}\n",
    "cv6 = GridSearchCV(pl6, parameters6, iid = False, cv=10)\n",
    "cv6.fit(x, y)\n",
    "\n",
    "print('best score:', end=\" \")\n",
    "print(cv6.best_score_)\n",
    "print('\\nbest params:', end=\" \")\n",
    "print(cv6.best_params_)\n",
    "print('\\nbest index:', end=\" \")\n",
    "print(cv6.best_index_)\n",
    "#print('\\nbest estimator:')\n",
    "#print(cv6.best_estimator_)\n",
    "#print(pd.DataFrame(data=cv6.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Parameter Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minMax: best score: 0.7153834115805946 {'svc__C': 0.9, gamma='scale'}\n",
    "\n",
    "lin minMax: best score: 0.7293298680974738 {'lsvc__C': 0.04}\n",
    "\n",
    "minMax SVC w/ linear kernel: best score: 0.7222071316789627 {'svc__C': 0.1, 'svc__kernel': 'linear'}\n",
    "\n",
    "robust: best score: 0.7322864967583278 {'svc__C': 0.01, 'svc__kernel': 'linear'}\n",
    "\n",
    "standard: best score: 0.7224463447350771 {'svc__C': 1, gamma='scale'}\n",
    "\n",
    "quantile: best score: 0.7337161860049184 {'svc__C': 0.09, 'svc__kernel': 'linear'}\n",
    "\n",
    "normal: best score: 0.6827246814218645 {'svc__C': 5, gamma='scale'}\n",
    "\n",
    "power: best score: 0.7182986809747373 {'svc__C': 1, gamma='scale'}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
