{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\caron\\OneDrive - University of North Carolina at Chapel Hill\\Honors Project\\CSV Files\\MRI Data.csv')\n",
    "temp = pd.concat([df.loc[0:, ['SDx']], df.loc[0:, 'L_LatVent': 'R_insula_surfavg']], axis=1, sort=False)\n",
    "temp = temp.dropna(how='any')\n",
    "df1 = temp.loc[0:, ['SDx']]\n",
    "df2 = temp.loc[0:, 'L_LatVent': 'R_insula_surfavg']\n",
    "y = np.array(df1).ravel()\n",
    "x = np.array(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SVC & minMax Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "minMax = MinMaxScaler()\n",
    "svc = SVC(probability=True, C=1.7, gamma='scale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "svm = Pipeline([('minMax', minMax), ('svc', svc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: All scores: "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.636154</td>\n",
       "      <td>0.043376</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.894166</td>\n",
       "      <td>0.077801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time params  \\\n",
       "0       0.636154      0.043376         0.012578        0.003308     {}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.885714           0.885714           0.790476           0.761905   \n",
       "\n",
       "   split4_test_score  split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0           0.819048           0.914286                1.0           0.942308   \n",
       "\n",
       "   split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.951923           0.990291         0.894166        0.077801   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using cross val because already know best params\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {}\n",
    "cv = GridSearchCV(svm, parameters, iid = False, cv=10)\n",
    "cv.fit(x, y)\n",
    "print('Results:', end=\" \")\n",
    "print('All scores:', end=\" \")\n",
    "pd.DataFrame(data=cv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting more detailed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.8941664888509548\n",
      "\n",
      "Maximum Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Average Score:', end=\" \")\n",
    "print(cv.best_score_) # best score is an average for scores from best estimator\n",
    "scores = cv.cv_results_ \n",
    "deletes = ['params', 'mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time']\n",
    "for i in deletes: # must remove dicts in results that have array that aren't score (i.e params is an array of dicts and can't compare to max)\n",
    "    scores.pop(i)\n",
    "max_score = 0\n",
    "for i in scores: # deteriming max\n",
    "    if (scores[i][0] > max_score):\n",
    "        max_score = scores[i][0]\n",
    "print('\\nMaximum Score:', end=\" \")\n",
    "print(max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescoring with all data post cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescore: 0.9588516746411483\n"
     ]
    }
   ],
   "source": [
    "#rescoring for all data\n",
    "print('Rescore:', end=\" \")\n",
    "print(cv.score(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting SDx for all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1041</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1042</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1043</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1044</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SDx\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "...   ...\n",
       "1040    3\n",
       "1041    3\n",
       "1042    3\n",
       "1043    3\n",
       "1044    3\n",
       "\n",
       "[1045 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=cv.predict(x), columns=[\"SDx\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shows probability of certain SDx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48123473e-07 9.99999852e-01]\n",
      "\n",
      "Subject 2 Prediction (negative): [0.92166051 0.07833949]\n"
     ]
    }
   ],
   "source": [
    "### print('Subject 1 Prediction (positive):', end=\" \")\n",
    "print(cv.predict_proba(np.array(x[1000:1001])).ravel())\n",
    "print('\\nSubject 2 Prediction (negative):', end=\" \")\n",
    "print(cv.predict_proba(np.array(x[50:51])).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 99.99...% subject 1 has condition\n",
    "* 92.01% subject 2 does not have condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
